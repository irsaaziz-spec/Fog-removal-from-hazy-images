# -*- coding: utf-8 -*-
"""Image_dehazing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sGNYMGvzwNUnlLmD6PZq1C8I_1RjNpnU
"""

# ============================================
# TRAINING WORKING MODEL
# ============================================

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import cv2
import matplotlib.pyplot as plt
import time
import os

# 1. Creating SIMPLE WORKING model
print("\n CREATING SIMPLE WORKING MODEL")

class SimpleWorkingDehazer(nn.Module):
    def __init__(self):
        super().__init__()
        # Very simple network that should work
        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)
        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)
        self.conv3 = nn.Conv2d(16, 8, 3, padding=1)
        self.conv4 = nn.Conv2d(8, 3, 3, padding=1)
        self.relu = nn.ReLU()

    def forward(self, x):
        residual = x
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = self.relu(self.conv3(x))
        x = self.conv4(x)
        return x + residual  # Residual connection helps

# 2. Create training data
print("\n CREATING TRAINING DATA")

def create_better_training_pair():
    """Create clean-hazy pairs that are easier to learn"""
    # Create clean image with simple patterns
    clean = np.random.rand(256, 256, 3).astype(np.float32)

    # Add some structure (gradients)
    for i in range(256):
        clean[i, :, 0] = i / 255.0 * 0.3 + 0.3  # Red gradient
        clean[:, i, 1] = i / 255.0 * 0.3 + 0.3  # Green gradient

    # Add haze (SIMPLE linear haze)
    haze_strength = np.random.uniform(0.4, 0.7)
    atmospheric = np.random.uniform(0.6, 0.8)

    hazy = clean * haze_strength + atmospheric

    # Add slight noise
    noise = np.random.randn(256, 256, 3) * 0.02
    hazy = np.clip(hazy + noise, 0, 1)

    return torch.from_numpy(hazy.transpose(2, 0, 1)).float(), \
           torch.from_numpy(clean.transpose(2, 0, 1)).float()

# 3. Train PROPERLY with monitoring
print("\n TRAINING WITH PROPER MONITORING")

model = SimpleWorkingDehazer()
criterion = nn.L1Loss()  # Better for image restoration
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Track progress
train_losses = []
val_losses = []

print("Training for 20 epochs (monitoring closely)...")
for epoch in range(20):
    # Training
    model.train()
    train_loss = 0

    for batch in range(50):  # 50 batches per epoch
        hazy, clean = create_better_training_pair()
        hazy = hazy.unsqueeze(0)
        clean = clean.unsqueeze(0)

        optimizer.zero_grad()
        output = model(hazy)
        loss = criterion(output, clean)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()

        if batch % 10 == 0:
            print(f"  Epoch {epoch+1:02d} | Batch {batch+1:03d}/50 | Loss: {loss.item():.4f}", end='\r')

    avg_train_loss = train_loss / 50
    train_losses.append(avg_train_loss)

    # Validation
    model.eval()
    val_loss = 0

    with torch.no_grad():
        for _ in range(10):
            hazy_val, clean_val = create_better_training_pair()
            hazy_val = hazy_val.unsqueeze(0)
            output_val = model(hazy_val)
            loss_val = criterion(output_val, clean_val.unsqueeze(0))
            val_loss += loss_val.item()

    avg_val_loss = val_loss / 10
    val_losses.append(avg_val_loss)

    print(f"\n Epoch {epoch+1:02d}/20 | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}")

    # Early stopping if loss is increasing
    if epoch > 5 and val_losses[-1] > val_losses[-2]:
        print(f"  Loss increased, stopping early")
        break

# 4. Save the working model
torch.save(model.state_dict(), 'working_dehazer.pth')
print(f"\n Working model saved: working_dehazer.pth")

# 5. TEST THOROUGHLY
print("\n THOROUGH TESTING")

model.eval()

# Test 1: Synthetic hazy image
print("Test 1: Synthetic haze removal...")
test_hazy, test_clean = create_better_training_pair()
test_hazy = test_hazy.unsqueeze(0)

with torch.no_grad():
    test_output = model(test_hazy)

# Calculate metrics
hazy_np = test_hazy[0].numpy().transpose(1, 2, 0)
clean_np = test_clean.numpy().transpose(1, 2, 0)
output_np = test_output[0].numpy().transpose(1, 2, 0)

hazy_error = np.mean(np.abs(clean_np - hazy_np))
output_error = np.mean(np.abs(clean_np - output_np))
improvement = ((hazy_error - output_error) / hazy_error) * 100

print(f"  • Hazy error: {hazy_error:.4f}")
print(f"  • Dehazed error: {output_error:.4f}")
print(f"  • Improvement: {improvement:+.1f}%")

if improvement > 0:
    print(f"   SUCCESS: Model improves quality!")
else:
    print(f"   FAILURE: Model degrades quality")

# Test 2: Realistic test
print("\nTest 2: More realistic test...")

def create_realistic_test():
    # Create scene with objects
    scene = np.zeros((256, 256, 3), dtype=np.float32)

    # Background gradient
    for i in range(256):
        scene[i, :, 0] = 0.3 + 0.3 * (i/256)  # Red
        scene[:, i, 1] = 0.3 + 0.3 * (i/256)  # Green

    # Add objects
    scene[50:100, 50:100, :] = [0.8, 0.2, 0.2]  # Red square
    scene[150:200, 150:200, :] = [0.2, 0.8, 0.2]  # Green square

    # Add haze
    haze_map = np.ones((256, 256)) * 0.5
    haze_map[100:200, 100:200] = 0.3  # Less haze in center

    atmospheric = 0.7
    hazy = scene * haze_map[..., np.newaxis] + atmospheric * (1 - haze_map[..., np.newaxis])

    return (torch.from_numpy(hazy.transpose(2, 0, 1)).float(),
            torch.from_numpy(scene.transpose(2, 0, 1)).float())

real_hazy, real_clean = create_realistic_test()
real_hazy = real_hazy.unsqueeze(0)

with torch.no_grad():
    real_output = model(real_hazy)

real_hazy_np = real_hazy[0].numpy().transpose(1, 2, 0)
real_clean_np = real_clean.numpy().transpose(1, 2, 0)
real_output_np = real_output[0].numpy().transpose(1, 2, 0)

real_hazy_error = np.mean(np.abs(real_clean_np - real_hazy_np))
real_output_error = np.mean(np.abs(real_clean_np - real_output_np))
real_improvement = ((real_hazy_error - real_output_error) / real_hazy_error) * 100

print(f"  • Realistic haziness: {real_hazy_error:.4f}")
print(f"  • After dehazing: {real_output_error:.4f}")
print(f"  • Improvement: {real_improvement:+.1f}%")

# 6. Visualize results
print("\n VISUALIZING RESULTS")

fig, axes = plt.subplots(2, 3, figsize=(12, 8))

# Test 1 visualization
axes[0, 0].imshow(np.clip(hazy_np, 0, 1))
axes[0, 0].set_title('Test 1: Hazy Input')
axes[0, 0].axis('off')
axes[0, 0].text(0.5, -0.1, f'Error: {hazy_error:.4f}',
                transform=axes[0, 0].transAxes, ha='center')

axes[0, 1].imshow(np.clip(output_np, 0, 1))
axes[0, 1].set_title('Dehazed Output')
axes[0, 1].axis('off')
axes[0, 1].text(0.5, -0.1, f'Error: {output_error:.4f}',
                transform=axes[0, 1].transAxes, ha='center')

axes[0, 2].imshow(np.clip(clean_np, 0, 1))
axes[0, 2].set_title('Ground Truth')
axes[0, 2].axis('off')

# Test 2 visualization
axes[1, 0].imshow(np.clip(real_hazy_np, 0, 1))
axes[1, 0].set_title('Test 2: Realistic Hazy')
axes[1, 0].axis('off')
axes[1, 0].text(0.5, -0.1, f'Error: {real_hazy_error:.4f}',
                transform=axes[1, 0].transAxes, ha='center')

axes[1, 1].imshow(np.clip(real_output_np, 0, 1))
axes[1, 1].set_title('Dehazed Output')
axes[1, 1].axis('off')
axes[1, 1].text(0.5, -0.1, f'Error: {real_output_error:.4f}',
                transform=axes[1, 1].transAxes, ha='center')

axes[1, 2].imshow(np.clip(real_clean_np, 0, 1))
axes[1, 2].set_title('Ground Truth')
axes[1, 2].axis('off')

plt.tight_layout()
plt.savefig('fixed_model_results.png', dpi=100, bbox_inches='tight')
plt.show()

# 7. Performance benchmark
print("\n⏱️ PERFORMANCE BENCHMARK")

times = []
for i in range(30):
    test_input = torch.randn(1, 3, 256, 256)

    start = time.time()
    with torch.no_grad():
        _ = model(test_input)
    end = time.time()

    times.append((end - start) * 1000)

avg_time = np.mean(times)
fps = 1000 / avg_time if avg_time > 0 else 0

print(f"  • Average inference time: {avg_time:.1f} ms")
print(f"  • FPS: {fps:.1f}")
print(f"  • Parameters: {sum(p.numel() for p in model.parameters()):,}")

# 8. Create Jetson-ready version
print("\n CREATING JETSON-READY VERSION")

# Save for Jetson
model_scripted = torch.jit.script(model)
model_scripted.save('fixed_dehazer_jetson.pt')
print(f" Jetson model saved: fixed_dehazer_jetson.pt")

# 9. Summary
print("\n" + "="*60)
print(" CRITICAL FIX COMPLETED!")
print("="*60)

if improvement > 0 and real_improvement > 0:
    print(f"""
 SUCCESS! Model now WORKS correctly:
────────────────────────────────────
1. Synthetic test: {improvement:+.1f}% improvement
2. Realistic test: {real_improvement:+.1f}% improvement
3. Inference speed: {avg_time:.1f} ms ({fps:.1f} FPS)
4. Model size: {sum(p.numel() for p in model.parameters()):,} parameters

 NEW FILES:
────────────
• working_dehazer.pth - Fixed working model
• fixed_dehazer_jetson.pt - Jetson version
• fixed_model_results.png - Test results

""")
else:
    print(f"""
  WARNING: Model still has issues
─────────────────────────────────
We need to try a different approach.
The model improvement is: {improvement:+.1f}%

""")

print("TESTING MODEL ON REAL WORLD IMAGES")
print("="*60)

import torch
import torch.nn as nn
import numpy as np
import cv2
import os
import matplotlib.pyplot as plt
from PIL import Image

# Load working model
print("\n LOADING WORKING MODEL")

class SimpleWorkingDehazer(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 8, 3, padding=1)
        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)
        self.conv3 = nn.Conv2d(16, 8, 3, padding=1)
        self.conv4 = nn.Conv2d(8, 3, 3, padding=1)
        self.relu = nn.ReLU()

    def forward(self, x):
        residual = x
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = self.relu(self.conv3(x))
        x = self.conv4(x)
        return x + residual

# Load model
model = SimpleWorkingDehazer()
model.load_state_dict(torch.load('working_dehazer.pth', map_location='cpu'))
model.eval()
print(" Model loaded successfully!")

# Defining image paths
print("\n DEFINE IMAGE PATHS")

YOUR_IMAGE_PATHS = [
    '/content/0099_0.9_0.16.jpg',
    '/content/1400_2.png',
    '/content/download.png',
]


# Processing function
def process_single_image(image_path, model, save_prefix='result'):
    """Process single image and save results"""
    print(f"\nProcessing: {os.path.basename(image_path)}")

    # Load image
    if not os.path.exists(image_path):
        print(f" Image not found: {image_path}")
        return None

    # Read and convert to RGB
    img = cv2.imread(image_path)
    if img is None:
        print(f" Could not read image: {image_path}")
        return None

    original_size = img.shape[:2]
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    print(f"  Original size: {original_size[1]}x{original_size[0]}")

    # Resize for model (256x256)
    img_resized = cv2.resize(img_rgb, (256, 256))
    img_normalized = img_resized.astype(np.float32) / 255.0

    # Convert to tensor
    img_tensor = torch.from_numpy(img_normalized.transpose(2, 0, 1)).float()
    img_tensor = img_tensor.unsqueeze(0)

    # Process
    with torch.no_grad():
        output_tensor = model(img_tensor)

    # Convert back
    output_np = output_tensor[0].numpy().transpose(1, 2, 0)
    output_np = np.clip(output_np, 0, 1)

    # Resize back to original
    output_resized = cv2.resize(output_np, (original_size[1], original_size[0]))
    output_uint8 = (output_resized * 255).astype(np.uint8)

    # Save results
    base_name = os.path.splitext(os.path.basename(image_path))[0]

    # Save original (RGB)
    cv2.imwrite(f'{save_prefix}_{base_name}_original.jpg',
                cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR))

    # Save dehazed result
    cv2.imwrite(f'{save_prefix}_{base_name}_dehazed.jpg',
                cv2.cvtColor(output_uint8, cv2.COLOR_RGB2BGR))

    # Save side-by-side comparison
    comparison = np.hstack([img_rgb, output_uint8])
    cv2.imwrite(f'{save_prefix}_{base_name}_comparison.jpg',
                cv2.cvtColor(comparison, cv2.COLOR_RGB2BGR))

    print(f" Saved: {save_prefix}_{base_name}_dehazed.jpg")
    print(f" Saved: {save_prefix}_{base_name}_comparison.jpg")

    return img_rgb, output_uint8

# Process all images
print("\n PROCESSING IMAGES")
print("="*60)

all_results = []
for i, img_path in enumerate(YOUR_IMAGE_PATHS):
    if os.path.exists(img_path):
        result = process_single_image(img_path, model, save_prefix=f'result_{i+1}')
        if result is not None:
            all_results.append((os.path.basename(img_path), result[0], result[1]))
    else:
        print(f"\n  Image not found: {img_path}")
        print("Please update the path or upload the image")

# Displaying results if we processed any images
if all_results:
    print("\n DISPLAYING RESULTS")

    num_images = len(all_results)
    fig, axes = plt.subplots(num_images, 3, figsize=(15, 5*num_images))

    if num_images == 1:
        axes = axes.reshape(1, -1)

    for idx, (name, original, dehazed) in enumerate(all_results):
        # Original
        axes[idx, 0].imshow(original)
        axes[idx, 0].set_title(f'{name}\nOriginal (Hazy)')
        axes[idx, 0].axis('off')

        # Dehazed
        axes[idx, 1].imshow(dehazed)
        axes[idx, 1].set_title('Dehazed Output')
        axes[idx, 1].axis('off')

        # Difference
        diff = np.abs(original.astype(np.float32) - dehazed.astype(np.float32))
        diff_normalized = diff / diff.max() if diff.max() > 0 else diff
        axes[idx, 2].imshow(diff_normalized, cmap='hot')
        axes[idx, 2].set_title('Difference Map')
        axes[idx, 2].axis('off')

    plt.tight_layout()
    plt.savefig('your_images_results.png', dpi=100, bbox_inches='tight')
    plt.show()

    print("\n All results saved!")
    print("Files created:")
    for file in os.listdir('.'):
        if file.startswith('result_') and file.endswith('.jpg'):
            print(f"  • {file}")
    print("  • your_images_results.png")
else:
    print("\n  No images were processed.")
    print("Please:")
    print("1. Upload your images to Colab")
    print("2. Update the YOUR_IMAGE_PATHS list above")
    print("3. Run this script again")

# 6. Quick test with sample if no images
print("\n QUICK TEST (If no images provided)")

# Create a test image
test_hazy = np.ones((400, 600, 3), dtype=np.uint8) * 180  # Gray haze
cv2.putText(test_hazy, 'TEST IMAGE', (150, 200),
           cv2.FONT_HERSHEY_SIMPLEX, 2, (100, 100, 100), 3)
cv2.rectangle(test_hazy, (100, 250), (300, 350), (150, 150, 150), -1)

# Save test image
cv2.imwrite('test_hazy_sample.jpg', test_hazy)
print(" Created test image: test_hazy_sample.jpg")

# Process it
test_original, test_dehazed = process_single_image('test_hazy_sample.jpg', model, 'test_sample')

if test_original is not None:
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    axes[0].imshow(test_original)
    axes[0].set_title('Test Hazy Input')
    axes[0].axis('off')

    axes[1].imshow(test_dehazed)
    axes[1].set_title('Dehazed Output')
    axes[1].axis('off')

    diff = np.abs(test_original.astype(np.float32) - test_dehazed.astype(np.float32))
    axes[2].imshow(diff, cmap='hot')
    axes[2].set_title('Difference')
    axes[2].axis('off')

    plt.tight_layout()
    plt.show()

print("\n" + "="*60)
print(" IMAGE TESTING COMPLETE!")
print("="*60)